{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_lab7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUSOyVZRWYK7",
        "colab_type": "code",
        "outputId": "947e58fb-e071-4489-a8b3-1db98009fd51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OddUg1iWYt6",
        "colab_type": "code",
        "outputId": "a85083d2-6045-4370-b8de-3095b5de6f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# !wget http://www.gutenberg.org/cache/epub/11/pg11.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-04 09:16:29--  http://www.gutenberg.org/cache/epub/11/pg11.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60422 (59K) [text/plain]\n",
            "Saving to: ‘pg11.txt’\n",
            "\n",
            "\rpg11.txt              0%[                    ]       0  --.-KB/s               \rpg11.txt            100%[===================>]  59.01K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-02-04 09:16:29 (1.23 MB/s) - ‘pg11.txt’ saved [60422/60422]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Duzez_kfJTA",
        "colab_type": "code",
        "outputId": "23269278-fb2f-4ae3-fed1-d384a2118086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBLpsFPLfSoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "filename = \"/content/drive/My Drive/Datasets/wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02z-X-vMfXb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integer\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fb2kvhugC4u",
        "colab_type": "code",
        "outputId": "8a45dfd2-e80a-4bbc-bc76-35af450f7690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  144507\n",
            "Total Vocab:  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNf4TP1igGZy",
        "colab_type": "code",
        "outputId": "bbfb94c1-a328-4d5b-f588-a6f4c6cf0bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  144407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCmo7iHKgPeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xhVNDCzgUre",
        "colab_type": "code",
        "outputId": "e0b5af17-6851-4e2e-d5bd-71cad7ba6ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBpMpswPggYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"/content/drive/My Drive/Models/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji7Ro76KgjTd",
        "colab_type": "code",
        "outputId": "9923778b-8016-4045-8388-0508db87df95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "144407/144407 [==============================] - 165s 1ms/step - loss: 2.9499\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.94989, saving model to /content/drive/My Drive/Models/weights-improvement-01-2.9499.hdf5\n",
            "Epoch 2/20\n",
            "144407/144407 [==============================] - 166s 1ms/step - loss: 2.7630\n",
            "\n",
            "Epoch 00002: loss improved from 2.94989 to 2.76303, saving model to /content/drive/My Drive/Models/weights-improvement-02-2.7630.hdf5\n",
            "Epoch 3/20\n",
            "144407/144407 [==============================] - 165s 1ms/step - loss: 2.6604\n",
            "\n",
            "Epoch 00003: loss improved from 2.76303 to 2.66040, saving model to /content/drive/My Drive/Models/weights-improvement-03-2.6604.hdf5\n",
            "Epoch 4/20\n",
            "144407/144407 [==============================] - 165s 1ms/step - loss: 2.5808\n",
            "\n",
            "Epoch 00004: loss improved from 2.66040 to 2.58079, saving model to /content/drive/My Drive/Models/weights-improvement-04-2.5808.hdf5\n",
            "Epoch 5/20\n",
            "144407/144407 [==============================] - 163s 1ms/step - loss: 2.5160\n",
            "\n",
            "Epoch 00005: loss improved from 2.58079 to 2.51598, saving model to /content/drive/My Drive/Models/weights-improvement-05-2.5160.hdf5\n",
            "Epoch 6/20\n",
            "144407/144407 [==============================] - 161s 1ms/step - loss: 2.4598\n",
            "\n",
            "Epoch 00006: loss improved from 2.51598 to 2.45981, saving model to /content/drive/My Drive/Models/weights-improvement-06-2.4598.hdf5\n",
            "Epoch 7/20\n",
            "144407/144407 [==============================] - 159s 1ms/step - loss: 2.4097\n",
            "\n",
            "Epoch 00007: loss improved from 2.45981 to 2.40966, saving model to /content/drive/My Drive/Models/weights-improvement-07-2.4097.hdf5\n",
            "Epoch 8/20\n",
            "144407/144407 [==============================] - 159s 1ms/step - loss: 2.3624\n",
            "\n",
            "Epoch 00008: loss improved from 2.40966 to 2.36235, saving model to /content/drive/My Drive/Models/weights-improvement-08-2.3624.hdf5\n",
            "Epoch 9/20\n",
            "144407/144407 [==============================] - 158s 1ms/step - loss: 2.3192\n",
            "\n",
            "Epoch 00009: loss improved from 2.36235 to 2.31917, saving model to /content/drive/My Drive/Models/weights-improvement-09-2.3192.hdf5\n",
            "Epoch 10/20\n",
            "144407/144407 [==============================] - 158s 1ms/step - loss: 2.2757\n",
            "\n",
            "Epoch 00010: loss improved from 2.31917 to 2.27572, saving model to /content/drive/My Drive/Models/weights-improvement-10-2.2757.hdf5\n",
            "Epoch 11/20\n",
            "144407/144407 [==============================] - 155s 1ms/step - loss: 2.2334\n",
            "\n",
            "Epoch 00011: loss improved from 2.27572 to 2.23345, saving model to /content/drive/My Drive/Models/weights-improvement-11-2.2334.hdf5\n",
            "Epoch 12/20\n",
            "144407/144407 [==============================] - 154s 1ms/step - loss: 2.1955\n",
            "\n",
            "Epoch 00012: loss improved from 2.23345 to 2.19549, saving model to /content/drive/My Drive/Models/weights-improvement-12-2.1955.hdf5\n",
            "Epoch 13/20\n",
            "144407/144407 [==============================] - 156s 1ms/step - loss: 2.1548\n",
            "\n",
            "Epoch 00013: loss improved from 2.19549 to 2.15481, saving model to /content/drive/My Drive/Models/weights-improvement-13-2.1548.hdf5\n",
            "Epoch 14/20\n",
            "144407/144407 [==============================] - 160s 1ms/step - loss: 2.1189\n",
            "\n",
            "Epoch 00014: loss improved from 2.15481 to 2.11890, saving model to /content/drive/My Drive/Models/weights-improvement-14-2.1189.hdf5\n",
            "Epoch 15/20\n",
            "144407/144407 [==============================] - 155s 1ms/step - loss: 2.0868\n",
            "\n",
            "Epoch 00015: loss improved from 2.11890 to 2.08677, saving model to /content/drive/My Drive/Models/weights-improvement-15-2.0868.hdf5\n",
            "Epoch 16/20\n",
            "144407/144407 [==============================] - 155s 1ms/step - loss: 2.0500\n",
            "\n",
            "Epoch 00016: loss improved from 2.08677 to 2.05004, saving model to /content/drive/My Drive/Models/weights-improvement-16-2.0500.hdf5\n",
            "Epoch 17/20\n",
            "144407/144407 [==============================] - 153s 1ms/step - loss: 2.0193\n",
            "\n",
            "Epoch 00017: loss improved from 2.05004 to 2.01933, saving model to /content/drive/My Drive/Models/weights-improvement-17-2.0193.hdf5\n",
            "Epoch 18/20\n",
            "144407/144407 [==============================] - 155s 1ms/step - loss: 1.9874\n",
            "\n",
            "Epoch 00018: loss improved from 2.01933 to 1.98739, saving model to /content/drive/My Drive/Models/weights-improvement-18-1.9874.hdf5\n",
            "Epoch 19/20\n",
            "144407/144407 [==============================] - 154s 1ms/step - loss: 1.9632\n",
            "\n",
            "Epoch 00019: loss improved from 1.98739 to 1.96315, saving model to /content/drive/My Drive/Models/weights-improvement-19-1.9632.hdf5\n",
            "Epoch 20/20\n",
            "144407/144407 [==============================] - 154s 1ms/step - loss: 1.9356\n",
            "\n",
            "Epoch 00020: loss improved from 1.96315 to 1.93564, saving model to /content/drive/My Drive/Models/weights-improvement-20-1.9356.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa239c397b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHyycejngvSm",
        "colab_type": "code",
        "outputId": "1f1a1e4e-4252-4a9e-9355-31aa6bea2008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "# load the network weights\n",
        "filename = \"/content/drive/My Drive/Models/weights-improvement-20-1.9356.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([chr[value] for value in pattern]), \"\\\"\")\n",
        "\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Seed:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-465ee34c7c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Seed:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-465ee34c7c99>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Seed:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYJ9q16Goa4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFrzEyILmyWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}